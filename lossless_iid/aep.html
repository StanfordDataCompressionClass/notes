<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Asymptotic Equipartition Property</title>


        <!-- Custom HTML head -->
        
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="../favicon.svg">
        <link rel="shortcut icon" href="../favicon.png">
        <link rel="stylesheet" href="../css/variables.css">
        <link rel="stylesheet" href="../css/general.css">
        <link rel="stylesheet" href="../css/chrome.css">
        <link rel="stylesheet" href="../css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="../FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="../fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="../highlight.css">
        <link rel="stylesheet" href="../tomorrow-night.css">
        <link rel="stylesheet" href="../ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="../././mdbook-admonish.css">
        <link rel="stylesheet" href=".././mdbook-admonish.css">

        <!-- MathJax -->
        <script async type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "../";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "light" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="../contents.html">EE274: Data Compression, course notes</a></li><li class="chapter-item expanded "><a href="../lossless_iid/coverpage.html"><strong aria-hidden="true">1.</strong> Lossless data compression: basics</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../lossless_iid/intro.html"><strong aria-hidden="true">1.1.</strong> Introduction</a></li><li class="chapter-item expanded "><a href="../lossless_iid/prefix_free_codes.html"><strong aria-hidden="true">1.2.</strong> Prefix Free Codes</a></li><li class="chapter-item expanded "><a href="../lossless_iid/kraft_ineq_and_optimality.html"><strong aria-hidden="true">1.3.</strong> Kraft Inequality</a></li><li class="chapter-item expanded "><a href="../lossless_iid/entropy.html"><strong aria-hidden="true">1.4.</strong> Entropy and Neg-log likelihood thumb rule</a></li><li class="chapter-item expanded "><a href="../lossless_iid/huffman.html"><strong aria-hidden="true">1.5.</strong> Huffman coding</a></li><li class="chapter-item expanded "><a href="../lossless_iid/aep.html" class="active"><strong aria-hidden="true">1.6.</strong> Asymptotic Equipartition Property</a></li><li class="chapter-item expanded "><a href="../lossless_iid/arithmetic_coding.html"><strong aria-hidden="true">1.7.</strong> Arithmetic coding</a></li><li class="chapter-item expanded "><a href="../lossless_iid/ans.html"><strong aria-hidden="true">1.8.</strong> Asymmetric Numeral Systems</a></li><li class="chapter-item expanded "><a href="../lossless_iid/non_iid_sources.html"><strong aria-hidden="true">1.9.</strong> Non IID Sources and Entropy Rate</a></li><li class="chapter-item expanded "><a href="../lossless_iid/context_based_coding.html"><strong aria-hidden="true">1.10.</strong> Context-based coding</a></li><li class="chapter-item expanded "><a href="../lossless_iid/lz77.html"><strong aria-hidden="true">1.11.</strong> Universal Compression with LZ77</a></li><li class="chapter-item expanded "><a href="../lossless_iid/practical_tips.html"><strong aria-hidden="true">1.12.</strong> Practical Tips on Lossless Compression</a></li></ol></li><li class="chapter-item expanded "><li class="spacer"></li><li class="chapter-item expanded "><a href="../lossy/coverpage.html"><strong aria-hidden="true">2.</strong> Lossy data Compression</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../lossy/quant.html"><strong aria-hidden="true">2.1.</strong> Basics and Quantization</a></li><li class="chapter-item expanded "><a href="../lossy/rd.html"><strong aria-hidden="true">2.2.</strong> Rate-Distortion Theory</a></li><li class="chapter-item expanded "><a href="../lossy/transform_coding_theory.html"><strong aria-hidden="true">2.3.</strong> Transform Coding Theory</a></li></ol></li><li class="chapter-item expanded "><li class="spacer"></li><li class="chapter-item expanded "><a href="../resources.html"><strong aria-hidden="true">3.</strong> Resources</a></li><li class="chapter-item expanded affix "><li class="spacer"></li><li class="chapter-item expanded "><a href="../homeworks/coverpage.html"><strong aria-hidden="true">4.</strong> Homeworks</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../homeworks/HW1.html"><strong aria-hidden="true">4.1.</strong> HW1</a></li><li class="chapter-item expanded "><a href="../homeworks/HW1_sol.html"><strong aria-hidden="true">4.2.</strong> HW1 Solution</a></li><li class="chapter-item expanded "><a href="../homeworks/HW2.html"><strong aria-hidden="true">4.3.</strong> HW2</a></li><li class="chapter-item expanded "><a href="../homeworks/HW2_sol.html"><strong aria-hidden="true">4.4.</strong> HW2 Solution</a></li><li class="chapter-item expanded "><a href="../homeworks/HW3.html"><strong aria-hidden="true">4.5.</strong> HW3</a></li><li class="chapter-item expanded "><a href="../homeworks/HW3_sol.html"><strong aria-hidden="true">4.6.</strong> HW3 Solution</a></li><li class="chapter-item expanded "><a href="../homeworks/HW4.html"><strong aria-hidden="true">4.7.</strong> HW4</a></li></ol></li><li class="chapter-item expanded "><li class="spacer"></li><li class="chapter-item expanded "><a href="../projects.html"><strong aria-hidden="true">5.</strong> Project</a></li><li class="chapter-item expanded affix "><li class="spacer"></li><li class="chapter-item expanded "><a href="../scl_tutorial/SCL_tutorial.html"><strong aria-hidden="true">6.</strong> SCL Tutorial</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../scl_tutorial/basics.html"><strong aria-hidden="true">6.1.</strong> SCL Basics</a></li><li class="chapter-item expanded "><a href="../scl_tutorial/exercise.html"><strong aria-hidden="true">6.2.</strong> SCL Exercise</a></li></ol></li><li class="chapter-item expanded "><li class="spacer"></li><li class="chapter-item expanded "><a href="../quiz_problems_2023.html"><strong aria-hidden="true">7.</strong> Quiz Problems (2023)</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title"></h1>

                    <div class="right-buttons">
                        <a href="../print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="asymptotic-equipartition-property"><a class="header" href="#asymptotic-equipartition-property">Asymptotic Equipartition Property</a></h1>
<p>We have been looking at the problem of data compression, algorithms for the same as well as fundamental limits on the compression rate. In this chapter we will approach the problem of data compression in a very different way. The basic idea of asymptotic equipartition property is to consider the space of all possible sequences produced by a stochastic (random) source, and focusing attention on the "typical" ones. The theory is asymptotic in the sense that many of the results focus on the regime of large source sequences. This technique allows us to recover many of the results for compression but in a non-constructive manner. Beyond compression, the same concept has allowed researchers to obtain powerful achievability and impossibility results even before a practical algorithm was developed. Our presentation here will focus on the main concepts, and present the mathematical intuition behind the results. We refer the reader to Chapter 3 in Cover and Thomas and to Information Theory lecture notes (available <a href="https://web.stanford.edu/class/ee376a/files/2017-18/lecture_4.pdf">here</a>) for some details and proofs.</p>
<p>Before we get started, we define the notation used throughout this chapter:</p>
<ol>
<li><strong>Alphabet</strong>: $\mathcal{U} = {1,2,\dots,r}$ specifies the possible values that the random variable of interest can take.</li>
<li><strong>iid source</strong>: An independent and identically distributed (iid) source produces a sequence of random variables that are independent of each other and have the same distribution, e.g. a sequence of tosses of a coin. We use $U_1, U_2, \dots \mathrm{iid} \sim U$ notation for iid random variables from distribution $U$.</li>
<li><strong>Source sequence</strong>: $U^n = (U_1,\dots,U_n)$ denotes the $n$-tuple representing $n$ source symbols, and $\mathcal{U}^n$ represents the set of all possible $U^n$. Note that we use lowercase $u^n$ for a particular realization of $U^n$.</li>
<li><strong>Probability</strong>: Under the iid source model, we simply have $P(U^n) = \Pi_{i=1}^n P(U_i)$ where we slightly abuse the notation by using $P$ to represent both the probability function of the $n$-tuple $U^n$ and that for a given symbol $U_i$.</li>
</ol>
<p>As an example, we could have alphabet $\mathcal{U} = {0, 1}$ and a source distributed iid according to $P(U_i = 0) = 0.3 = 1- P(U_i = 1)$. Then the source sequence $u^3 = (1,0,0)$ has probability $0.7\times0.3\times0.3=0.063$.</p>
<p>Before we start the discussion of asymptotic equipartition property and typical sequences, let us recall the (weak) law of large numbers (LLN) that says the empirical average of a sequence of random variables converges towards their expectation (to understand the different types of convergence of random variables and the strong LLN, please refer to a probability textbook).</p>
<div id="admonition-theorem-1-weak-law-of-large-numbers" class="admonition admonish-example" role="note" aria-labelledby="admonition-theorem-1-weak-law-of-large-numbers-title">
<div class="admonition-title">
<div id="admonition-theorem-1-weak-law-of-large-numbers-title">
<p>Theorem-1: Weak Law of Large Numbers</p>
</div>
<a class="admonition-anchor-link" href="#admonition-theorem-1-weak-law-of-large-numbers"></a>
</div>
<div>
<p>For $U_1, U_2, \dots \mathrm{iid} \sim U$ with alphabet $\mathcal{U} = {1,2,\dots,r}$, we have the following for any $\epsilon &gt; 0$:
$$\lim_{n\rightarrow \infty} \mathrm{P}\left(\left|\frac{1}{n}\sum_{i=1}^n {U_i} - E[U]\right| &lt; \epsilon \right) = 1$$</p>
</div>
</div>
<p>That is for arbitarily small $\epsilon &gt; 0$, as $n$ becomes large, the probability that the empirical average is within $\epsilon$ of the expectation is $1$.</p>
<p>With this background, we are ready to jump in!</p>
<h2 id="the-epsilon-typical-set"><a class="header" href="#the-epsilon-typical-set">The $\epsilon$-typical set</a></h2>
<div id="admonition-definition-1" class="admonition admonish-example" role="note" aria-labelledby="admonition-definition-1-title">
<div class="admonition-title">
<div id="admonition-definition-1-title">
<p>Definition-1</p>
</div>
<a class="admonition-anchor-link" href="#admonition-definition-1"></a>
</div>
<div>
<p>For some $\epsilon &gt; 0$, the source sequence $U^n$ is <strong>$\epsilon$-typical</strong> if
$$\left|-\frac{1}{n}\log P(U^n) - H(U)\right| \leq \epsilon$$</p>
</div>
</div>
Recall that $H(U)$ is the entropy of the random variable $U$. It is easy to see that the condition is equivalent to saying that $2^{-n(H(U)+\epsilon)} \leq P(U^n) \leq 2^{-n(H(U)-\epsilon)}$. The set of all **$\epsilon$-typical** sequences is called the **$\epsilon$-typical set** denoted as $A_{\epsilon}^{(n)}$. Put in words, the **$\epsilon$-typical set** contains all $n$-length sequences whose probability is close to $2^{-nH(U)}$. 
<p>Next, we look at some probabilities of the typical set:</p>
<div id="admonition-theorem-2-properties-of-typical-sets" class="admonition admonish-example" role="note" aria-labelledby="admonition-theorem-2-properties-of-typical-sets-title">
<div class="admonition-title">
<div id="admonition-theorem-2-properties-of-typical-sets-title">
<p>Theorem-2: Properties of typical sets</p>
</div>
<a class="admonition-anchor-link" href="#admonition-theorem-2-properties-of-typical-sets"></a>
</div>
<div>
<p>For any $\epsilon &gt; 0$,</p>
<ol>
<li>$\lim_{n\rightarrow \infty} P(U^n \in A_{\epsilon}^{(n)}) = 1$.</li>
<li>$\left|A_{\epsilon}^{(n)}\right| \leq 2^{n(H(U)+\epsilon)}$</li>
<li>For large enough $n$, $\left|A_{\epsilon}^{(n)}\right| \geq (1-\epsilon)2^{n(H(U)-\epsilon)}$</li>
</ol>
<p>Simply put, this is saying that for large $n$, the typical set has probability close to $1$ and size roughly $2^{n(H(U)}$</p>
</div>
</div>
<h3 id="proof-sketch-for-theorem-2"><a class="header" href="#proof-sketch-for-theorem-2">Proof sketch for Theorem-2</a></h3>
<ol>
<li>This follows directly from the Weak LLN by noting the definition of typical sequences and the following facts:
(i) $-\frac{1}{n}\log P(U^n) = \frac{1}{n}\sum - \log P(U_i)$ (since this is iid).
(ii) $H(U) = E[-\log P(U)]$ from the definition of entropy.
Thus applying the LLN on $-\log P(U)$ instead of $U$ directly gives the desired result.</li>
</ol>
<p>Both 2 &amp; 3 follow from the definition of typical sequences (which roughly says the probability of each typical sequence is close to $2^{-nH(U)}$) and the fact that the typical set has probability close to $1$ (less than $1$ just because total probability is atmost $1$ and close to $1$ due to property 1).</p>
<h3 id="intuition-into-the-typical-set"><a class="header" href="#intuition-into-the-typical-set">Intuition into the typical set</a></h3>
<p>To gain intuition into the typical set and its properties, let $|\mathcal{U}| = r$ and consider the set of all $n$ length sequences $U^n$ with size $r^n$. Then the AEP says that (for $n$ sufficiently large), all the probability mass is concentrated in an exponentially smaller subset of size $2^{nH(U)}$. That is,
$$\frac{|A_{\epsilon}^{(n)}|}{|\mathcal{U}^n|} \approx \frac{2^{nH(U)}}{r^n} = 2^{-n(\log r - H(U))}$$</p>
<p>Furthermore, all the elements in the typical set $A_{\epsilon}^{(n)}$ are roughly equiprobable, each with probability $2^{-nH(U)}$. Thus, $\mathcal{U}^n$ contains within itself a subset that contains almost the entire probability mass, and within the subset the elements are roughly uniformly distributed. It is important to note that these properties hold only for large enough $n$ since ultimately these are derived from the law of large numbers. The intuition into typical sets is illustrated in the figure below.</p>
<img src="images/typical_set.png" style="border:1px solid black;" alt="Typical set">
<div id="admonition-quiz-1-intuition-into-the-typical-set" class="admonition admonish-question" role="note" aria-labelledby="admonition-quiz-1-intuition-into-the-typical-set-title">
<div class="admonition-title">
<div id="admonition-quiz-1-intuition-into-the-typical-set-title">
<p>Quiz-1: Intuition into the typical set</p>
</div>
<a class="admonition-anchor-link" href="#admonition-quiz-1-intuition-into-the-typical-set"></a>
</div>
<div>
<p>What does the elements of the typical set look like?</p>
<ol>
<li>Consider a binary source with $P(0)=P(1)=0.5$. What is the size of the typical set $A_{\epsilon}^{(n)}$ (Hint: this doesn't depend on $\epsilon$!)? Which elements of ${0,1}^n$ are typical? After looking at this example, can you still claim the typical set is exponentially smaller than the set of all sequences <em>in all cases</em>?</li>
<li>Now consider a binary source with $P(0)=1-P(1)=0.2$. Recalling the fact that typical elements have probability around $2^{-nH(U)}$, what can you say about the elements of the typical set? (Hint: what fraction of zeros and ones would you expect a <em>typical</em> sequence to have? Check if your intuition matches with the $2^{-nH(U)}$ expression.)</li>
<li>In part 2, you can easily verify that the most probable sequence is the sequence consisting of all $1$s. Is that sequence typical (for small $\epsilon$)? If not, how do you square that off with the fact that the typical set contains almost all of the probability mass?</li>
</ol>
</div>
</div>
<p>Before we discuss the ramifications of the above for compressibility of sequences, we introduce one further property of subsets of $\mathcal{U}^n$. This property says that any set substantially smaller than the typical set has negligible probability mass. Intuitively this holds because all elements in the typical set have roughly the same probability, and hence removing a large fraction of them leaves very little probability mass remaining. In other words, very roughly the property says that the typical set is the smallest set containing most of the probability. This property will be very useful below when we link typical sets to compression. Here we just state the theorem and leave the proof to the references.</p>
<div id="admonition-theorem-2-sets-exponentially-smaller-than-the-typical-set" class="admonition admonish-example" role="note" aria-labelledby="admonition-theorem-2-sets-exponentially-smaller-than-the-typical-set-title">
<div class="admonition-title">
<div id="admonition-theorem-2-sets-exponentially-smaller-than-the-typical-set-title">
<p>Theorem-2: Sets exponentially smaller than the typical set</p>
</div>
<a class="admonition-anchor-link" href="#admonition-theorem-2-sets-exponentially-smaller-than-the-typical-set"></a>
</div>
<div>
<p>Fix $\delta &gt; 0$ and $B^{(n)} \subseteq \mathcal{U}^n$ such that $|B^{(n)}| \leq 2^{n(H(U)-\delta)}$. Then
$$\lim_{n\rightarrow \infty} P(U^n \in B^{(n)}) = 0$$</p>
</div>
</div>
<h2 id="compression-based-on-typical-sets"><a class="header" href="#compression-based-on-typical-sets">Compression based on typical sets</a></h2>
<p>Suppose you were tasked with developing a compressor for a source with $2^k$ possible values, each of them equally likely to occur. It is easy to verify that a simple fixed-length code that encodes each of the value with $k$ bits is optimal for this source. But, if you think about the AEP property above, as $n$ grows, almost all the probability in the set of $n$-length sequences over alphabet $\mathcal{U}$ is contained in the typical set with roughly $2^k$ elements (where $k=nH(U)$). And the elements within the typical set are (roughly) equally likely to occur. Ignoring the non-typical elements for a moment, we can encode the typical elements with $nH(U)$ bits using the simple logic mentioned earlier. We have encoded $n$ input symbols with $nH(U)$ bits, effectively using $H(U)$ bits/symbol! This was not truly lossless because we fail to represent the non-typical sequences. But this can be considered near-lossless since the non-typical sequences have probability close to $0$, and hence this code is lossless for a given input with very high probability. Note that we ignored the $\epsilon$'s and $\delta$'s in the treatment above, but that shouldn't take away from the main conclusions that become truer and truer as $n$ grows.</p>
<p>On the flip side, suppose we wanted to encode the elements in $\mathcal{U}$ with $n(H(U)-\delta)$ bits for some $\delta &gt; 0$. Now, $n(H(U)-\delta)$ bits can represent $2^{n(H(U)-\delta)}$ elements. But according to theorem 2 above, the set of elements correctly represented by such a code has negligible probability as $n$ grows. This means a fixed-length code using less than $H(U)$ bits per symbol is unable to losslessly represent an input sequence with very high probability. Thus, using AEP we can prove the fact that any fixed-length <em>near-lossless</em> compression scheme must use at least $H(U)$ bits per symbol.</p>
<h3 id="lossless-compression-scheme"><a class="header" href="#lossless-compression-scheme">Lossless compression scheme</a></h3>
<p>Let us now develop a lossless compression algorithm based on the AEP, this time being very precise. As before, we focus on encoding sequences of length $n$. Note that a lossless compression algorithm aiming to achieve entropy must be variable length (unless the source itself is uniformly distributed). And the AEP teaches us that elements in the typical set should ideally be represented using $\approx nH(U)$ bits. With this in mind, consider the following scheme:</p>
<div id="admonition-lossless-compression-using-typical-sets" class="admonition admonish-info" role="note" aria-labelledby="admonition-lossless-compression-using-typical-sets-title">
<div class="admonition-title">
<div id="admonition-lossless-compression-using-typical-sets-title">
<p>Lossless compression using typical sets</p>
</div>
<a class="admonition-anchor-link" href="#admonition-lossless-compression-using-typical-sets"></a>
</div>
<div>
<p>Fix $\epsilon &gt; 0$, and assign index $idx$ ranging from $1,\dots,|A_{\epsilon}^{(n)}|$ to the elements in $A_{\epsilon}^{(n)}$ (the order doesn't matter). In addition, define a fixed length code $fixed$ for $\mathcal{U}^n$ that uses $n\log_2 |\mathcal{U}|$ bits to encode any input sequence. Now the encoding of $u^n$ is simply:</p>
<ul>
<li>if $u^n \in A_{\epsilon}^{(n)}$, encode as $0$ followed by $idx(u^n)$</li>
<li>else, encode as $1$ followed by $fixed(u^n)$</li>
</ul>
</div>
</div>
<p>Let's calculate the expected code length (in bits per symbol) used by the above scheme. For $n$ large enough, we can safely assume that $P(U^n \in A_{\epsilon}^{(n)}) \geq 1-\epsilon$ by the AEP. Furthermore, we know that $idx(u^n)$ needs at most $H(U) + \epsilon$ bits to represent (theorem-1 part 2). Thus, denoting the code length by $l$, we have
$$E[l(U^n)] \leq (1-\epsilon)(1+n(H(U) + \epsilon)) + \epsilon (1+n\log_2 |\mathcal{U}|)$$
where the first term corresponds to the typical sequences and the second term to everything else (not that we use the simplest possible encoding for non-typical sequences since they don't really matter in terms of their probability). Also note that we add $1$ to each of the lengths to account for the $0$ or $1$ we prefix in the scheme above. Simplifying the above, we have
$$\frac{E[l(U^n)]}{n} = (1-\epsilon)(H(U) + \epsilon) + \epsilon \log_2 |\mathcal{U}| + \frac{1}{n}$$
$$\frac{E[l(U^n)]}{n} = H(U) + O(\epsilon) + \frac{1}{n}$$
where $O(\epsilon)$ represents terms bounded by $c\epsilon$ for some constant $c$ when $\epsilon$ is small. Thus we can achieve code lengths arbitrary close to $H(U)$ bits/symbol by selecting $\epsilon$ and $n$ appropriately!</p>
<div id="admonition-quiz-2-lossless-compression-based-on-typical-sets" class="admonition admonish-question" role="note" aria-labelledby="admonition-quiz-2-lossless-compression-based-on-typical-sets-title">
<div class="admonition-title">
<div id="admonition-quiz-2-lossless-compression-based-on-typical-sets-title">
<p>Quiz-2: Lossless compression based on typical sets</p>
</div>
<a class="admonition-anchor-link" href="#admonition-quiz-2-lossless-compression-based-on-typical-sets"></a>
</div>
<div>
<ol>
<li>Describe the decoding algorithm for the above scheme and verify that the scheme is indeed lossless.</li>
<li>What is the complexity of the encoding and decoding procedure as a function of $n$? Consider both the time and memory usage. Is this a practical scheme for large values of $n$?</li>
</ol>
</div>
</div>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="../lossless_iid/huffman.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>

                            <a rel="next" href="../lossless_iid/arithmetic_coding.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="../lossless_iid/huffman.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

                    <a rel="next" href="../lossless_iid/arithmetic_coding.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>




        <script type="text/javascript">
            window.playground_copyable = true;
        </script>


        <script src="../elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../searcher.js" type="text/javascript" charset="utf-8"></script>

        <script src="../clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="../book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        <script type="text/javascript" src="../mermaid.min.js"></script>
        <script type="text/javascript" src="../mermaid-init.js"></script>


    </body>
</html>
